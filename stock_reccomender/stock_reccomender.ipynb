{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock reccomender\n",
    "Steve Smith\n",
    "Jan 2025\n",
    "\n",
    "The purpose of this is to build an AI agent that will reccomend stocks, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  item  language  number_issues  recommendation_score\n",
      "0    A       0.2            0.7              1.000000\n",
      "1    B       0.8            0.1              0.391862\n",
      "2    C       0.3            0.5              0.965843\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get user langauges\n",
    "import requests\n",
    "\n",
    "def get_user_languages(username, token=None):\n",
    "    \"\"\"Fetch unique programming languages from a GitHub user's repositories.\"\"\"\n",
    "    headers = {\"Authorization\": f\"token {token}\"} if token else {}\n",
    "\n",
    "    # Get user repositories\n",
    "    repos_url = f\"https://api.github.com/users/{username}/repos\"\n",
    "    response = requests.get(repos_url, headers=headers)\n",
    "    repos = response.json()\n",
    "\n",
    "    languages = set()\n",
    "\n",
    "    # Fetch languages for each repo\n",
    "    for repo in repos:\n",
    "        lang_url = repo[\"languages_url\"]\n",
    "        lang_response = requests.get(lang_url, headers=headers)\n",
    "        repo_languages = lang_response.json().keys()\n",
    "        languages.update(repo_languages)\n",
    "\n",
    "    return languages\n",
    "\n",
    "# Replace 'octocat' with any GitHub username\n",
    "username = \"octocat\"  \n",
    "languages = get_user_languages(username)\n",
    "\n",
    "print(f\"{username} uses: {languages}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configgithub import API_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def summarize_user_langs(tracking_dict):\n",
    "    user_langs_df = pd.Series(tracking_dict).reset_index()\n",
    "    user_langs_df.columns = ['Language', 'Bites']\n",
    "    total_bytes=np.sum(user_langs_df['Bites'])\n",
    "\n",
    "    user_langs_df['prop_bites']=user_langs_df['Bites']/total_bytes\n",
    "    return user_langs_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from github import Github\n",
    "\n",
    "# Authenticate (Optional: Use a GitHub token for higher rate limits)\n",
    "g = Github(API_KEY)\n",
    "\n",
    "# Languages are stored on a per-repo basis as language : bites\n",
    "# Need to loop through each USER's repo and tally up total bites per language\n",
    "def get_languages(username):\n",
    "    user = g.get_user(username)\n",
    "    tracking_dict={}\n",
    "\n",
    "    # May want to break this into def?\n",
    "    # also move any per-repo GETS here\n",
    "    for i in user.get_repos():\n",
    "        langs= i.get_languages()\n",
    "        for key, value in langs.items():\n",
    "            tracking_dict[key] = tracking_dict.get(key, 0) + value\n",
    "    \n",
    "    # convert to df and tally prop of bites per langauge\n",
    "    user_l_df= summarize_user_langs(tracking_dict)\n",
    "    \n",
    "    return user_l_df\n",
    "\n",
    "languages_sbs87 = get_languages(\"sbs87\")\n",
    "languages_octo = get_languages(\"octocat\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages_octo['user']='octo'\n",
    "languages_sbs87['user']='sbs87'\n",
    "\n",
    "test_in=pd.concat([languages_octo,languages_sbs87])[[\"Language\",\"user\",\"prop_bites\"]].pivot(index='user', columns='Language', values='prop_bites').fillna(0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Language</th>\n",
       "      <th>user</th>\n",
       "      <th>C++</th>\n",
       "      <th>CSS</th>\n",
       "      <th>HTML</th>\n",
       "      <th>JavaScript</th>\n",
       "      <th>Jupyter Notebook</th>\n",
       "      <th>Perl</th>\n",
       "      <th>PostScript</th>\n",
       "      <th>Python</th>\n",
       "      <th>R</th>\n",
       "      <th>Ruby</th>\n",
       "      <th>Shell</th>\n",
       "      <th>TeX</th>\n",
       "      <th>recommendation_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>octo</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066412</td>\n",
       "      <td>0.019270</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.910062</td>\n",
       "      <td>0.004042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sbs87</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.639653</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.329618</td>\n",
       "      <td>0.00144</td>\n",
       "      <td>0.010033</td>\n",
       "      <td>0.006111</td>\n",
       "      <td>0.004195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002339</td>\n",
       "      <td>0.006188</td>\n",
       "      <td>0.01879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Language   user       C++       CSS      HTML  JavaScript  Jupyter Notebook  \\\n",
       "0          octo  0.000000  0.066412  0.019270    0.000213          0.000000   \n",
       "1         sbs87  0.000166  0.000107  0.639653    0.000149          0.329618   \n",
       "\n",
       "Language     Perl  PostScript    Python         R      Ruby     Shell  \\\n",
       "0         0.00000    0.000000  0.000000  0.000000  0.910062  0.004042   \n",
       "1         0.00144    0.010033  0.006111  0.004195  0.000000  0.002339   \n",
       "\n",
       "Language       TeX  recommendation_score  \n",
       "0         0.000000               1.00000  \n",
       "1         0.006188               0.01879  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix = cosine_similarity(test_in.iloc[:, 1:])\n",
    "test_in[\"recommendation_score\"] = similarity_matrix[0]\n",
    "test_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  user  language  recommendation_score\n",
      "0    A       0.2                   1.0\n",
      "1    B       0.8                   1.0\n",
      "2    C       0.3                   1.0\n"
     ]
    }
   ],
   "source": [
    "# github reccomender DO NOT COMMIT\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "# Sample dataset\n",
    "df = pd.DataFrame({\n",
    "    \"user\": [\"A\", \"B\", \"C\"],\n",
    "    \"language\": [0.2, 0.8, 0.3],\n",
    "    \"number_issues\": [0.7, 0.1, 0.5]\n",
    "})\n",
    "\n",
    "# Compute similarity\n",
    "similarity_matrix = cosine_similarity(df.iloc[:, 1:])\n",
    "df[\"recommendation_score\"] = similarity_matrix[0]  # Similarity to item A\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_users_and_repos(since=0, per_page=5, token=None):\n",
    "    \"\"\"Fetch a list of users and their public repositories.\"\"\"\n",
    "    headers = {\"Authorization\": f\"token {token}\"} if token else {}\n",
    "    \n",
    "    # Step 1: Get public users\n",
    "    users_url = f\"https://api.github.com/users?since={since}&per_page={per_page}\"\n",
    "    users_response = requests.get(users_url, headers=headers)\n",
    "    users = users_response.json()\n",
    "\n",
    "    user_repos = {}\n",
    "\n",
    "    # Step 2: Get each user's repositories\n",
    "    for user in users:\n",
    "        username = user[\"login\"]\n",
    "        repos_url = f\"https://api.github.com/users/{username}/repos\"\n",
    "        repos_response = requests.get(repos_url, headers=headers)\n",
    "        repos = repos_response.json()\n",
    "\n",
    "        # Extract repo names\n",
    "        user_repos[username] = [repo[\"name\"] for repo in repos]\n",
    "\n",
    "    return user_repos\n",
    "\n",
    "# Fetch 5 users and their repos\n",
    "users_repos = get_users_and_repos(per_page=5)\n",
    "print(users_repos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep learning\n",
    "import tensorflow_recommenders as tfrs\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load MovieLens dataset\n",
    "ratings = tf.data.Dataset.from_tensor_slices({\n",
    "    \"user_id\": [\"1\", \"2\", \"3\"],\n",
    "    \"movie_id\": [\"101\", \"102\", \"103\"],\n",
    "    \"rating\": [4.0, 5.0, 3.0]\n",
    "})\n",
    "\n",
    "# Define user and movie embeddings\n",
    "user_model = tf.keras.Sequential([tf.keras.layers.StringLookup(vocabulary=[\"1\", \"2\", \"3\"]), tf.keras.layers.Embedding(3, 16)])\n",
    "movie_model = tf.keras.Sequential([tf.keras.layers.StringLookup(vocabulary=[\"101\", \"102\", \"103\"]), tf.keras.layers.Embedding(3, 16)])\n",
    "\n",
    "# Train a ranking model\n",
    "model = tfrs.models.Model(user_model, movie_model)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vv/lg2w1mmx79b93kh1fxk_v5p00000gn/T/ipykernel_13003/3395647669.py:5: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  pd.options.mode.use_inf_as_na = True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-05-15 06:00 AM</td>\n",
       "      <td>8723.8</td>\n",
       "      <td>8793.0</td>\n",
       "      <td>8714.9</td>\n",
       "      <td>8739.0</td>\n",
       "      <td>8988053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-05-15 07:00 AM</td>\n",
       "      <td>8739.0</td>\n",
       "      <td>8754.8</td>\n",
       "      <td>8719.3</td>\n",
       "      <td>8743.0</td>\n",
       "      <td>2288904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-05-15 08:00 AM</td>\n",
       "      <td>8743.0</td>\n",
       "      <td>8743.1</td>\n",
       "      <td>8653.2</td>\n",
       "      <td>8723.7</td>\n",
       "      <td>8891773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-05-15 09:00 AM</td>\n",
       "      <td>8723.7</td>\n",
       "      <td>8737.8</td>\n",
       "      <td>8701.2</td>\n",
       "      <td>8708.1</td>\n",
       "      <td>2054868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-05-15 10:00 AM</td>\n",
       "      <td>8708.1</td>\n",
       "      <td>8855.7</td>\n",
       "      <td>8695.8</td>\n",
       "      <td>8784.4</td>\n",
       "      <td>17309722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58178</th>\n",
       "      <td>2025-01-02 09:00 PM</td>\n",
       "      <td>97378.0</td>\n",
       "      <td>97394.0</td>\n",
       "      <td>97128.0</td>\n",
       "      <td>97262.0</td>\n",
       "      <td>174426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58179</th>\n",
       "      <td>2025-01-02 10:00 PM</td>\n",
       "      <td>97261.0</td>\n",
       "      <td>97261.0</td>\n",
       "      <td>96777.0</td>\n",
       "      <td>97000.0</td>\n",
       "      <td>1611671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58180</th>\n",
       "      <td>2025-01-02 11:00 PM</td>\n",
       "      <td>96984.0</td>\n",
       "      <td>97106.0</td>\n",
       "      <td>96871.0</td>\n",
       "      <td>97035.0</td>\n",
       "      <td>490811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58181</th>\n",
       "      <td>2025-01-03 12:00 AM</td>\n",
       "      <td>97035.0</td>\n",
       "      <td>97101.0</td>\n",
       "      <td>96872.0</td>\n",
       "      <td>96911.0</td>\n",
       "      <td>2174059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58182</th>\n",
       "      <td>2025-01-03 01:00 AM</td>\n",
       "      <td>96911.0</td>\n",
       "      <td>96912.0</td>\n",
       "      <td>96792.0</td>\n",
       "      <td>96792.0</td>\n",
       "      <td>240531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58183 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date     open     high      low    close    volume\n",
       "0      2018-05-15 06:00 AM   8723.8   8793.0   8714.9   8739.0   8988053\n",
       "1      2018-05-15 07:00 AM   8739.0   8754.8   8719.3   8743.0   2288904\n",
       "2      2018-05-15 08:00 AM   8743.0   8743.1   8653.2   8723.7   8891773\n",
       "3      2018-05-15 09:00 AM   8723.7   8737.8   8701.2   8708.1   2054868\n",
       "4      2018-05-15 10:00 AM   8708.1   8855.7   8695.8   8784.4  17309722\n",
       "...                    ...      ...      ...      ...      ...       ...\n",
       "58178  2025-01-02 09:00 PM  97378.0  97394.0  97128.0  97262.0    174426\n",
       "58179  2025-01-02 10:00 PM  97261.0  97261.0  96777.0  97000.0   1611671\n",
       "58180  2025-01-02 11:00 PM  96984.0  97106.0  96871.0  97035.0    490811\n",
       "58181  2025-01-03 12:00 AM  97035.0  97101.0  96872.0  96911.0   2174059\n",
       "58182  2025-01-03 01:00 AM  96911.0  96912.0  96792.0  96792.0    240531\n",
       "\n",
       "[58183 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensortrade.data.cdd import CryptoDataDownload\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.use_inf_as_na = True\n",
    "\n",
    "def prepare_data(df):\n",
    "    df['volume'] = np.int64(df['volume'])\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df.sort_values(by='date', ascending=True, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df['date'] = df['date'].dt.strftime('%Y-%m-%d %I:%M %p')\n",
    "    return df\n",
    "\n",
    "#   CryptoDataDownload  Parameters\n",
    "#         ----------\n",
    "#         exchange_name : str\n",
    "#             The name of the exchange.\n",
    "#         base_symbol : str\n",
    "#             The base symbol fo the cryptocurrency pair.\n",
    "#         quote_symbol : str\n",
    "#             The quote symbol fo the cryptocurrency pair.\n",
    "#         timeframe : {\"d\", \"h\", \"m\"}\n",
    "#             The timeframe to collect data from.\n",
    "#         include_all_volumes : bool, optional\n",
    "#             Whether or not to include both base and quote volume.\n",
    "\n",
    "#         Returns\n",
    "#         -------\n",
    "#         `pd.DataFrame`\n",
    "#             A open, high, low, close and volume for the specified exchange and\n",
    "#             cryptocurrency pair.\n",
    "#         \"\"\"\n",
    "\n",
    "def fetch_data(exchange_name=\"Bitfinex\",quote_symbol=\"BTC\",timeframe=\"1h\"):\n",
    "    # simulated data for now?\n",
    "    cdd = CryptoDataDownload()\n",
    "    bitfinex_data = cdd.fetch(exchange_name, \"USD\", quote_symbol, timeframe)\n",
    "    bitfinex_data = bitfinex_data[['date', 'open', 'high', 'low', 'close', 'volume']]\n",
    "    bitfinex_data = prepare_data(bitfinex_data)\n",
    "    return bitfinex_data\n",
    "\n",
    "def load_csv(filename):\n",
    "    df = pd.read_csv('data/' + filename, skiprows=1)\n",
    "    df.drop(columns=['symbol', 'volume_btc'], inplace=True)\n",
    "\n",
    "    # Fix timestamp from \"2019-10-17 09-AM\" to \"2019-10-17 09-00-00 AM\"\n",
    "    df['date'] = df['date'].str[:14] + '00-00 ' + df['date'].str[-2:]\n",
    "\n",
    "    return prepare_data(df)\n",
    "\n",
    "#TODO : play with data size parameters such as timefrome (increases number of rows)\n",
    "#TODO: make sure parameters confrom to the acceptable set\n",
    "market_data = fetch_data(timeframe=\"1h\")\n",
    "market_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "githubmatcher",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
